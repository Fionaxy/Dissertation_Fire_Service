{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71ce6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"/Users/fionamac/Documents/GEOG0105/data for Xinyan inc details.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1f1ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/anaconda3/envs/envGEOG0051/lib/python3.10/site-packages (3.1.2)\r\n",
      "Requirement already satisfied: et-xmlfile in /opt/anaconda3/envs/envGEOG0051/lib/python3.10/site-packages (from openpyxl) (1.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838cd8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2706 entries, 0 to 2705\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   incident_number  2706 non-null   object\n",
      " 1   details          2704 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 42.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f79f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Still need to built a stop words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb5fe1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38 entries, 0 to 37\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   CallSign      38 non-null     object \n",
      " 1   Station name  38 non-null     object \n",
      " 2   Easting       38 non-null     float64\n",
      " 3   Northing      38 non-null     float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_excel(\"/Users/fionamac/Documents/GEOG0105/Stations as of August 2014 - LOCATION UPDATED.xlsx\")\n",
    "df2.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402abf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = dict(zip(df2['CallSign'], df2['Station name']))\n",
    "\n",
    "text= df['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b1659e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36dcfb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5599cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/fionamac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33c6a0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/fionamac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/fionamac/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Create a new column with preprocessed text\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/envGEOG0051/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/envGEOG0051/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/envGEOG0051/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/envGEOG0051/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_text\u001b[39m(text):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Convert text to lowercase\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Remove numbers and punctuation\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mtranslate(\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, string\u001b[38;5;241m.\u001b[39mdigits \u001b[38;5;241m+\u001b[39m string\u001b[38;5;241m.\u001b[39mpunctuation))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers and punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.digits + string.punctuation))\n",
    "    \n",
    "    # Tokenize text (split into individual words)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words and short words (length < 3)\n",
    "    words = [w for w in words if w not in stop_words and len(w) > 2]\n",
    "    \n",
    "    # Lemmatize words\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    \n",
    "    # Join words back into a string\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Create a new column with preprocessed text\n",
    "df['clean_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4368de14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/fionamac/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "text = str(df['details'])  # 将df['details']转换为字符串\n",
    "tokens = word_tokenize(text)  # 分词\n",
    "pos_tags = pos_tag(tokens)  # 词性标注\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d88d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_text = []\n",
    "for word, tag in pos_tags:\n",
    "    if word in mapping_dict:\n",
    "        replaced_text.append(mapping_dict[word])\n",
    "    else:\n",
    "        replaced_text.append(word)\n",
    "\n",
    "replaced_text = \" \".join(replaced_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "294625c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       CALLER HEARD A BANG IN THE GARDEN AND NOW THER...\n",
       "1       SMOKE COMING UNDER FOOTPATH _x0001_OFF CHAUCER...\n",
       "2       LARGE VAN GONE INTO THE BACK OF A BUS _x0001_F...\n",
       "3            RBC 3_x0001_NEIGHBOURS CAR_x0001_ON DRIVEWAY\n",
       "4                                        NO SMOKE OR FIRE\n",
       "                              ...                        \n",
       "2701    ALARM IS CONTINUOUSLY - HAS HAPPENED AFTER THE...\n",
       "2702    CALL FROM HEADTEACHER_x0001_SMELL COMING INTO ...\n",
       "2703    FLOODING AT STATION, CREWS UNABLE TO LEAVE WHI...\n",
       "2704                                           MAIN ALARM\n",
       "2705                               FIRE ON NATURE RESERVE\n",
       "Name: details, Length: 2706, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fb08f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        incident_number                                            details  \\\n",
      "0     FW009151-11022023  CALLER HEARD A BANG IN THE GARDEN AND NOW THER...   \n",
      "1     FW002000-11012023  SMOKE COMING UNDER FOOTPATH _x0001_OFF CHAUCER...   \n",
      "2     FW008087-07022023  LARGE VAN GONE INTO THE BACK OF A BUS _x0001_F...   \n",
      "3     FW003321-18012023       RBC 3_x0001_NEIGHBOURS CAR_x0001_ON DRIVEWAY   \n",
      "4     FW006753-01022023                                   NO SMOKE OR FIRE   \n",
      "...                 ...                                                ...   \n",
      "2701  FW013464-01032023  ALARM IS CONTINUOUSLY - HAS HAPPENED AFTER THE...   \n",
      "2702  FW013539-01032023  CALL FROM HEADTEACHER_x0001_SMELL COMING INTO ...   \n",
      "2703  FW013545-01032023  FLOODING AT STATION, CREWS UNABLE TO LEAVE WHI...   \n",
      "2704  FW013566-01032023                                         MAIN ALARM   \n",
      "2705  FW013570-01032023                             FIRE ON NATURE RESERVE   \n",
      "\n",
      "                                                   text  \\\n",
      "0     CALLER HEARD A BANG IN THE GARDEN AND NOW THER...   \n",
      "1     SMOKE COMING UNDER FOOTPATH _x0001_OFF CHAUCER...   \n",
      "2     LARGE VAN GONE INTO THE BACK OF A BUS _x0001_F...   \n",
      "3          RBC 3_x0001_NEIGHBOURS CAR_x0001_ON DRIVEWAY   \n",
      "4                                      NO SMOKE OR FIRE   \n",
      "...                                                 ...   \n",
      "2701  ALARM IS CONTINUOUSLY - HAS HAPPENED AFTER THE...   \n",
      "2702  CALL FROM HEADTEACHER_x0001_SMELL COMING INTO ...   \n",
      "2703  FLOODING AT STATION, CREWS UNABLE TO LEAVE WHI...   \n",
      "2704                                         MAIN ALARM   \n",
      "2705                             FIRE ON NATURE RESERVE   \n",
      "\n",
      "                                          replaced_text  \n",
      "0     CALLER HEARD A BANG IN THE GARDEN AND NOW THER...  \n",
      "1     SMOKE COMING UNDER FOOTPATH _x0001_OFF CHAUCER...  \n",
      "2     LARGE VAN GONE INTO THE BACK OF A BUS _x0001_F...  \n",
      "3          RBC 3_x0001_NEIGHBOURS CAR_x0001_ON DRIVEWAY  \n",
      "4                                      NO SMOKE OR FIRE  \n",
      "...                                                 ...  \n",
      "2701  ALARM IS CONTINUOUSLY - HAS HAPPENED AFTER THE...  \n",
      "2702  CALL FROM HEADTEACHER_x0001_SMELL COMING INTO ...  \n",
      "2703  FLOODING AT STATION , CREWS UNABLE TO LEAVE WH...  \n",
      "2704                                         MAIN ALARM  \n",
      "2705                             FIRE ON NATURE RESERVE  \n",
      "\n",
      "[2706 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df['replaced_text'] = \"\"\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    text = str(row['details'])\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "\n",
    "    replaced_text = []\n",
    "    for word, tag in pos_tags:\n",
    "        if word in mapping_dict:\n",
    "            replaced_text.append(mapping_dict[word])\n",
    "        else:\n",
    "            replaced_text.append(word)\n",
    "\n",
    "    replaced_text = \" \".join(replaced_text)\n",
    "    df.at[i, 'replaced_text'] = replaced_text\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da1e6da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/fionamac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/fionamac/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/fionamac/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers and punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.digits + string.punctuation))\n",
    "    \n",
    "    # Tokenize text (split into individual words)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words and short words (length < 3)\n",
    "    words = [w for w in words if w not in stop_words and len(w) > 2]\n",
    "    \n",
    "    # Lemmatize words\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    \n",
    "    # Join words back into a string\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Create a new column with preprocessed text\n",
    "df['clean_text'] = df['replaced_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5850e145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          caller heard bang garden flame\n",
       "1                 smoke coming footpath xoff chaucer road\n",
       "2       large van gone back bus xfuel leakage fromn bu...\n",
       "3                         rbc xneighbours carxon driveway\n",
       "4                                              smoke fire\n",
       "                              ...                        \n",
       "2701    alarm continuously happened power gone xrented...\n",
       "2702    call headteacherxsmell coming one classroom ge...\n",
       "2703    flooding station crew unable leave whilst attm...\n",
       "2704                                           main alarm\n",
       "2705                                  fire nature reserve\n",
       "Name: clean_text, Length: 2706, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05f3268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'clean_data2.csv'\n",
    "df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e6ad2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Word  Frequency\n",
      "25                fire       1002\n",
      "5                smoke        537\n",
      "60               alarm        411\n",
      "21                 rbc        366\n",
      "39                 car        357\n",
      "...                ...        ...\n",
      "824           firexbut          1\n",
      "2954      xinformation          1\n",
      "2955         mcsweeney          1\n",
      "822   smokexdownstairs          1\n",
      "5446        attmepting          1\n",
      "\n",
      "[5447 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/fionamac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 假设df是一个有效的Pandas DataFrame对象，包含名为'clean text'的列\n",
    "\n",
    "# 将'clean text'列中的文本合并为一个字符串\n",
    "text = ' '.join(df['clean_text'])\n",
    "\n",
    "# 分词\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# 计算词频\n",
    "word_freq = Counter(tokens)\n",
    "\n",
    "# 创建一个新的DataFrame来存储词频结果\n",
    "freq_df = pd.DataFrame(list(word_freq.items()), columns=['Word', 'Frequency'])\n",
    "\n",
    "# 按词频降序排序\n",
    "freq_df = freq_df.sort_values('Frequency', ascending=False)\n",
    "\n",
    "print(freq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666cdb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec1eeb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将freq_df保存为CSV文件\n",
    "freq_df.to_csv('word_frequency.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1deb1509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fire</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>smoke</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>alarm</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rbc</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>car</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>female</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>set</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>sounding</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>attendance</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Frequency\n",
       "25         fire       1002\n",
       "5         smoke        537\n",
       "60        alarm        411\n",
       "21          rbc        366\n",
       "39          car        357\n",
       "..          ...        ...\n",
       "435      female         58\n",
       "33          set         58\n",
       "302    sounding         58\n",
       "248     kitchen         57\n",
       "92   attendance         57\n",
       "\n",
       "[70 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df.head(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "786b3e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0.028*\"speech\" + 0.019*\"smoke\" + 0.018*\"contact\" + 0.017*\"careline\" + 0.014*\"see\" + 0.014*\"fire\" + 0.013*\"main\" + 0.011*\"caller\" + 0.010*\"house\" + 0.010*\"panel\"\n",
      "Topic 1: 0.051*\"car\" + 0.022*\"log\" + 0.020*\"trapped\" + 0.016*\"person\" + 0.016*\"route\" + 0.014*\"rbc\" + 0.014*\"amb\" + 0.014*\"xpol\" + 0.014*\"rtc\" + 0.013*\"xamb\"\n",
      "Topic 2: 0.014*\"road\" + 0.010*\"alarm\" + 0.010*\"fire\" + 0.009*\"xcaller\" + 0.008*\"old\" + 0.007*\"house\" + 0.007*\"bathroom\" + 0.007*\"smoke\" + 0.006*\"locked\" + 0.006*\"burnt\"\n",
      "Topic 3: 0.074*\"fire\" + 0.037*\"alarm\" + 0.035*\"smoke\" + 0.015*\"sign\" + 0.012*\"property\" + 0.012*\"xcaller\" + 0.012*\"floor\" + 0.012*\"flat\" + 0.011*\"caller\" + 0.011*\"xno\"\n",
      "Topic 4: 0.032*\"vehicle\" + 0.023*\"flat\" + 0.015*\"floor\" + 0.015*\"car\" + 0.012*\"gas\" + 0.012*\"rtc\" + 0.011*\"inside\" + 0.011*\"road\" + 0.010*\"fire\" + 0.009*\"old\"\n",
      "Topic 5: 0.033*\"fire\" + 0.026*\"rbc\" + 0.017*\"log\" + 0.017*\"police\" + 0.016*\"xfire\" + 0.010*\"door\" + 0.010*\"xpolice\" + 0.009*\"xamb\" + 0.008*\"call\" + 0.008*\"stuck\"\n",
      "Topic 6: 0.031*\"stuck\" + 0.014*\"rbc\" + 0.011*\"lift\" + 0.011*\"near\" + 0.010*\"door\" + 0.008*\"unable\" + 0.008*\"ring\" + 0.008*\"house\" + 0.007*\"fire\" + 0.007*\"locked\"\n",
      "Topic 7: 0.059*\"fire\" + 0.020*\"smoke\" + 0.019*\"rbc\" + 0.015*\"bin\" + 0.014*\"alarm\" + 0.013*\"road\" + 0.012*\"xno\" + 0.012*\"outside\" + 0.011*\"sign\" + 0.009*\"floor\"\n",
      "Topic 8: 0.034*\"fire\" + 0.033*\"smoke\" + 0.015*\"car\" + 0.014*\"rbc\" + 0.011*\"inside\" + 0.010*\"property\" + 0.009*\"road\" + 0.009*\"contact\" + 0.008*\"near\" + 0.008*\"left\"\n",
      "Topic 9: 0.027*\"fire\" + 0.026*\"road\" + 0.022*\"rbc\" + 0.016*\"car\" + 0.010*\"alarm\" + 0.009*\"garden\" + 0.008*\"xpol\" + 0.008*\"smoke\" + 0.008*\"xamb\" + 0.008*\"attendance\"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "# Define preprocessing function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers and punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.digits + string.punctuation))\n",
    "    \n",
    "    # Tokenize text (split into individual words)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words and short words (length < 3)\n",
    "    words = [w for w in words if w not in stop_words and len(w) > 2]\n",
    "    \n",
    "    # Lemmatize words\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# Preprocess text and create dictionary and corpus for LDA\n",
    "df['tokens'] = df['clean_text'].apply(preprocess_text)\n",
    "dictionary = Dictionary(df['tokens'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['tokens']]\n",
    "\n",
    "# Train LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10)\n",
    "\n",
    "# Print topics and top words in each topic\n",
    "for i, topic in lda_model.show_topics(formatted=True, num_topics=10, num_words=10):\n",
    "    print(f'Topic {i}: {topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77cedb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.1-cp38-cp38-macosx_10_9_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.7.0 in /opt/anaconda3/envs/envGEOG0115/lib/python3.8/site-packages (from gensim) (1.9.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m781.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/envs/envGEOG0115/lib/python3.8/site-packages (from gensim) (1.23.3)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.1 smart-open-6.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7428ade6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       CALLER HEARD A BANG IN THE GARDEN AND NOW THER...\n",
       "1       SMOKE COMING UNDER FOOTPATH _x0001_OFF CHAUCER...\n",
       "2       LARGE VAN GONE INTO THE BACK OF A BUS _x0001_F...\n",
       "3            RBC 3_x0001_NEIGHBOURS CAR_x0001_ON DRIVEWAY\n",
       "4                                        NO SMOKE OR FIRE\n",
       "                              ...                        \n",
       "2701    ALARM IS CONTINUOUSLY - HAS HAPPENED AFTER THE...\n",
       "2702    CALL FROM HEADTEACHER_x0001_SMELL COMING INTO ...\n",
       "2703    FLOODING AT STATION, CREWS UNABLE TO LEAVE WHI...\n",
       "2704                                           MAIN ALARM\n",
       "2705                               FIRE ON NATURE RESERVE\n",
       "Name: text, Length: 2706, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5034a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35a8c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0e6e6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      frequency\n",
      "word                           \n",
      "the                        1334\n",
      "fire                       1004\n",
      "in                          899\n",
      "on                          859\n",
      "of                          805\n",
      "...                         ...\n",
      "yrs_x0001_ref                 1\n",
      "telecare_x0001_burnt          1\n",
      "mayfield                      1\n",
      "peugout                       1\n",
      "attmepting                    1\n",
      "\n",
      "[6622 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 处理文本列，将NaN值替换为空字符串\n",
    "df['text'] = df['text'].fillna('')\n",
    "\n",
    "# 将文本列拼接成一个字符串\n",
    "text_combined = ' '.join(df['text'])\n",
    "\n",
    "# 使用正则表达式分割文本为单词\n",
    "words = re.findall(r'\\b\\w+\\b', text_combined.lower())  # 转为小写以统一词频\n",
    "\n",
    "# 计算词频\n",
    "word_freq = Counter(words)\n",
    "\n",
    "# 将词频转为DataFrame\n",
    "word_freq_df = pd.DataFrame.from_dict(word_freq, orient='index', columns=['frequency'])\n",
    "word_freq_df.index.name = 'word'\n",
    "\n",
    "# 根据词频降序排序\n",
    "word_freq_df = word_freq_df.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# 打印词频统计结果\n",
    "print(word_freq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fa20be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设您已经有了DataFrame df，其中包含了'text'列\n",
    "# 如果没有'text2'列，请先创建它\n",
    "df['text2'] = df['text'].str.replace('_x0001_', ' ')\n",
    "\n",
    "# 打印包含新列的DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fc7587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              frequency\n",
      "word                   \n",
      "the                1341\n",
      "fire               1226\n",
      "in                  930\n",
      "on                  898\n",
      "of                  806\n",
      "...                 ...\n",
      "plasterboard          1\n",
      "brickwork             1\n",
      "gallon                1\n",
      "6213                  1\n",
      "attmepting            1\n",
      "\n",
      "[4400 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 处理文本列，将NaN值替换为空字符串\n",
    "df['text2'] = df['text2'].fillna('')\n",
    "\n",
    "# 将文本列拼接成一个字符串\n",
    "text_combined = ' '.join(df['text2'])\n",
    "\n",
    "# 使用正则表达式分割文本为单词\n",
    "words = re.findall(r'\\b\\w+\\b', text_combined.lower())  # 转为小写以统一词频\n",
    "\n",
    "# 计算词频\n",
    "word_freq = Counter(words)\n",
    "\n",
    "# 将词频转为DataFrame\n",
    "word_freq_df = pd.DataFrame.from_dict(word_freq, orient='index', columns=['frequency'])\n",
    "word_freq_df.index.name = 'word'\n",
    "\n",
    "# 根据词频降序排序\n",
    "word_freq_df = word_freq_df.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# 打印词频统计结果\n",
    "print(word_freq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c4840e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              word  frequency\n",
      "5              the       1341\n",
      "39            fire       1226\n",
      "4               in        930\n",
      "35              on        898\n",
      "24              of        806\n",
      "...            ...        ...\n",
      "2406  plasterboard          1\n",
      "2408     brickwork          1\n",
      "2413        gallon          1\n",
      "2414          6213          1\n",
      "4399    attmepting          1\n",
      "\n",
      "[4400 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 创建新的DataFrame存储词频和词语\n",
    "word_freq_data = []\n",
    "\n",
    "# 处理文本列，将NaN值替换为空字符串\n",
    "df['text2'] = df['text2'].fillna('')\n",
    "\n",
    "# 将文本列拼接成一个字符串\n",
    "text_combined = ' '.join(df['text2'])\n",
    "\n",
    "# 使用正则表达式分割文本为单词\n",
    "words = re.findall(r'\\b\\w+\\b', text_combined.lower())  # 转为小写以统一词频\n",
    "\n",
    "# 计算词频\n",
    "word_freq = Counter(words)\n",
    "\n",
    "# 将词频和词语存储到新的DataFrame中\n",
    "for word, freq in word_freq.items():\n",
    "    word_freq_data.append({'word': word, 'frequency': freq})\n",
    "\n",
    "word_freq_df = pd.DataFrame(word_freq_data)\n",
    "\n",
    "# 根据词频降序排序\n",
    "word_freq_df = word_freq_df.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# 打印词频统计结果\n",
    "print(word_freq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b66c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将freq_df保存为CSV文件\n",
    "word_freq_df.to_csv('word_frequency_with_replacement.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f36f847c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       CALLER HEARD A BANG IN THE GARDEN AND NOW THER...\n",
       "1           SMOKE COMING UNDER FOOTPATH  OFF CHAUCER ROAD\n",
       "2       LARGE VAN GONE INTO THE BACK OF A BUS  FUEL LE...\n",
       "3                        RBC 3 NEIGHBOURS CAR ON DRIVEWAY\n",
       "4                                        NO SMOKE OR FIRE\n",
       "                              ...                        \n",
       "2701    ALARM IS CONTINUOUSLY - HAS HAPPENED AFTER THE...\n",
       "2702    CALL FROM HEADTEACHER SMELL COMING INTO ONE CL...\n",
       "2703    FLOODING AT STATION, CREWS UNABLE TO LEAVE WHI...\n",
       "2704                                           MAIN ALARM\n",
       "2705                               FIRE ON NATURE RESERVE\n",
       "Name: text2, Length: 2706, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text2']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
